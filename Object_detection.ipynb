{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c541e39-5abd-44d8-b50e-2fae7a6fca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the YOLO\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1388bc2d-7f41-4338-8576-df1ea54c6715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Briefly displaying architecture\n",
    "\n",
    "model = YOLO(\"yolov8n.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030bc72-0399-4df8-a289-2755cb306886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model for 100 epochs, training is halted at nearly 70th epoch\n",
    "\n",
    "model.train(data=\"data/data.yaml\", epochs=100, batch=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf48199-b0d0-4fb5-9439-39faea887b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running inference on a given video\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "video_path = \"Highway_cars.mp4\"\n",
    "cap = cv2.VideoCapture(\"Highway_cars.mp4\")\n",
    "\n",
    "ret, frame = cap.read()\n",
    "H, W, _ = frame.shape\n",
    "video_path_out = '{}_output.mp4'.format(video_path)\n",
    "out = cv2.VideoWriter(video_path_out, cv2.VideoWriter_fourcc(*'MP4V'), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))\n",
    "\n",
    "model_path = os.path.join('.', 'runs', 'colab_runs', 'runs', 'detect', 'train2','weights','best.pt')\n",
    "model = YOLO(model_path)\n",
    "\n",
    "threshold = 0.3\n",
    "while ret:\n",
    "    results = model(frame)[0]\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "        if score > threshold:\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 255), 2)\n",
    "            cv2.putText(frame, f\"{score:.2f}% {results.names[int(class_id)].lower()}\", (int(x1), int(y1 - 8)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    out.write(frame)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548ec199-d422-49d0-8d7e-26df473c889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impoting libraries for reading and visualizing metrics data\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bf4e17-77aa-4fbf-be27-401c6cf4fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the metrics metadata\n",
    "\n",
    "df = pd.read_csv(\"runs/detect/train/results.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3676ff-bc83-4ba6-8847-c5621841e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing metrics\n",
    "\n",
    "%matplotlib inline\n",
    "fig, axes = plt.subplots(nrows=len(df.columns), ncols=1, figsize=(10, 6 * len(df.columns)))\n",
    "for i, col in enumerate(df.columns):\n",
    "    axes[i].plot(df[col], marker='o', linestyle='-', color='b')\n",
    "    axes[i].set_title(f'{col}', fontsize=16, fontweight='bold')\n",
    "    axes[i].set_xlabel('Index', fontsize=12)\n",
    "    axes[i].set_ylabel(col, fontsize=12)\n",
    "    axes[i].grid(True)\n",
    "    \n",
    "    axes[i].tick_params(axis='both', which='major', labelsize=10)\n",
    "    axes[i].axhline(y=df[col].mean(), color='r', linestyle='--', label='Mean')\n",
    "    axes[i].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
